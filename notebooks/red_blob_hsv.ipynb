{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MAIN PIPELINE: Oil Palm Fruit Detection and Analysis (4-stage unified system)\n",
    "- SECTION 1: Under-canopy fruit detection (YOLO)\n",
    "- SECTION 2: Over-canopy zoomed frame extraction (crown-based)\n",
    "- SECTION 3: Heading recalibration to bin images (based on Ground Truth to drone starting position)\n",
    "- SECTION 4: Red-blob masking + analysis (grey/blob overlays)\n",
    "- SECTION 5: Final scoring of Ground Truth vs Orbit results (binary + quantitative accuracy)\n",
    "    Compute Orbit Score (dumb method)\n",
    "    For each point's orbits:\n",
    "    Mark all frames where max_blob_grey > THRESHOLD as “spikes.”\n",
    "    Map each image's index to its compass section, count unique sections.\n",
    "    Score 2 if ≥5 unique sections or any opposing-section pair; Score 1 if ≥1; Score 0 otherwise.\n",
    "\"\"\"\n",
    "\n",
    "# ─── IMPORTS ───────────────────────────────────────────────────────\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import contextlib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ─── TOGGLE WHAT TO RUN ──────────────────────────────────────────────\n",
    "PROCESS_IMAGES = False\n",
    "PROCESS_VIDEOS = False\n",
    "RECALIBRATE_HEADING = False\n",
    "EXTRACT_REDBLOB = True\n",
    "FINAL_ANALYSIS = True\n",
    "\n",
    "# ─── CONFIGURATION ───────────────────────────────────────────────────\n",
    "BASE_DATE = \"16_7_2025\"\n",
    "GT_DATE = \"16_7_2025\"\n",
    "images_per_quadrant = 7 \n",
    "TARGET_TIME = 2.0    # Time in seconds to begin extracting frames from video\n",
    "REFERENCE_ANGLE = 0  # North\n",
    "ZOOM_FACTOR = 6      # Zoom factor for over-canopy images\n",
    "THRESHOLD = 2000      # Minimum area for a blob to be considered valid\n",
    "\n",
    "# ─── PATHS ───────────────────────────────────────────────────────────\n",
    "BASE_PATH = Path(f\"/Users/at/Orbit_Red_Blob/Data/UKE_Plot_14_DD_{BASE_DATE}\")\n",
    "GT_IMAGE_CSV = BASE_PATH / f\"Input/Geo_Tag/GT_UnderCanopy_{GT_DATE}.csv\"\n",
    "GT_VIDEO_CSV = BASE_PATH / f\"input/Geo_Tag/GT_OverCanopy_{GT_DATE}.csv\"\n",
    "INPUT_IMAGE_FOLDER = BASE_PATH / \"Input/Ground_Truth_Pictures\"\n",
    "VIDEO_INPUT_DIR = BASE_PATH / \"Input/Orbit_Videos\"\n",
    "SRT_PATH = VIDEO_INPUT_DIR\n",
    "VIDEO_NAME = \"VIDEO_NAME2\"\n",
    "\n",
    "MODEL_PATH = Path(\"/Users/at/Orbit_Red_Blob/models/TR2_Ripe_V8.pt\")\n",
    "CROWN_MODEL_PATH = Path(\"/Users/at/Orbit_Red_Blob/models/orbit_crownv8.pt\")\n",
    "\n",
    "OUTPUT_BASE = BASE_PATH / \"output_hsv/Trees\"\n",
    "GT_LOG_CSV = BASE_PATH / \"output_hsv/Analysis/GT_log.csv\"\n",
    "LOG_CSV_PATH = BASE_PATH / \"output_hsv/Analysis/image_log.csv\"\n",
    "FINAL_OUTPUT_PATH = BASE_PATH / \"output_hsv/Analysis/final_analysis.csv\"\n",
    "\n",
    "# # ─── HSV THRESHOLDS 1 ──────────────────────────────────────────────────\n",
    "# lower_red1 = np.array([0, 100, 20])\n",
    "# upper_red1 = np.array([10, 255, 150])\n",
    "# lower_red2 = np.array([160, 100, 25])\n",
    "# upper_red2 = np.array([179, 255, 188])\n",
    "\n",
    "\n",
    "# ─── HSV THRESHOLDS 2 ──────────────────────────────────────────────────\n",
    "lower_red1 = np.array([0, 50, 50])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([160, 50, 50])\n",
    "upper_red2 = np.array([179, 255, 255])\n",
    "\n",
    "# ─── SECTION MAP ─────────────────────────────────────────────────────\n",
    "SECTION_MAP = {\n",
    "    1: [\"30\", \"31\", \"y+\", \"1\"],\n",
    "    2: [\"2\", \"3\", \"4\", \"5\"],\n",
    "    3: [\"6\", \"7\", \"8\", \"9\"],\n",
    "    4: [\"10\", \"11\", \"12\", \"13\"],\n",
    "    5: [\"14\", \"15\", \"16\", \"17\"],\n",
    "    6: [\"18\", \"19\", \"20\", \"21\"],\n",
    "    7: [\"22\", \"23\", \"24\", \"25\"],\n",
    "    8: [\"26\", \"27\", \"28\", \"29\"],\n",
    "}\n",
    "OPPOSITE_SECTIONS = {1: 5, 2: 6, 3: 7, 4: 8, 5: 1, 6: 2, 7: 3, 8: 4}\n",
    "image_to_section = {img: sec for sec, imgs in SECTION_MAP.items() for img in imgs}\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SECTION 1: Under-canopy image detection\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def process_gt_images():\n",
    "    model = YOLO(str(MODEL_PATH))\n",
    "    all_imgs = {f.stem.upper(): f for f in INPUT_IMAGE_FOLDER.glob(\"*.jpg\")}\n",
    "    all_imgs.update({f.stem.upper(): f for f in INPUT_IMAGE_FOLDER.glob(\"*.JPG\")})\n",
    "    df = pd.read_csv(GT_IMAGE_CSV)\n",
    "    gt_log_entries, count_by_tree = [], {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        tree_num, image_name_raw = row.get(\"Tree\"), row.get(\"IMG\")\n",
    "        if pd.isna(tree_num) or pd.isna(image_name_raw): continue\n",
    "\n",
    "        point_name = f\"point{int(tree_num)}\"\n",
    "        image_name = image_name_raw.strip().upper()\n",
    "        count_by_tree.setdefault(point_name, 0)\n",
    "        count_by_tree[point_name] += 1\n",
    "        suffix = count_by_tree[point_name]\n",
    "        if image_name not in all_imgs:\n",
    "            print(f\"❌ Image not found: {image_name}\")\n",
    "            continue\n",
    "\n",
    "        input_path = all_imgs[image_name]\n",
    "        output_dir = OUTPUT_BASE / point_name / \"predictions\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_name = f\"{image_name}_{suffix}.jpg\"\n",
    "        output_path = output_dir / out_name\n",
    "\n",
    "        try:\n",
    "            results = model(str(input_path), verbose=False)[0]\n",
    "            img = cv2.imread(str(input_path))\n",
    "            ripe, unripe = 0, 0\n",
    "\n",
    "            for box in results.boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                label = model.names[cls].lower()\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                color = (0, 0, 255) if label == \"ripe\" else (255, 0, 0)\n",
    "                if label == \"ripe\": ripe += 1\n",
    "                elif label == \"unripe\": unripe += 1\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 40)\n",
    "\n",
    "            cv2.imwrite(str(output_path), img)\n",
    "            gt_log_entries.append({\"point\": point_name, \"image_name\": out_name, \"Ripe\": ripe, \"Unripe\": unripe})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {image_name}: {e}\")\n",
    "            gt_log_entries.append({\"point\": point_name, \"image_name\": out_name, \"Ripe\": 0, \"Unripe\": 0})\n",
    "\n",
    "    GT_LOG_CSV.parent.mkdir(parents=True, exist_ok=True)  # Create the directory if needed\n",
    "    pd.DataFrame(gt_log_entries).to_csv(GT_LOG_CSV, index=False)\n",
    "    print(f\"✅ GT log saved to: {GT_LOG_CSV}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SECTION 2: Over-canopy video frame extraction\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def detect_crown_center(image, model, conf_thresh=0.5, previous_center=None):\n",
    "    with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "        results = model(image, verbose=False)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    if boxes is None or len(boxes.xyxy) == 0:\n",
    "        return None\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    x_min_valid = 0.25 * w\n",
    "    x_max_valid = 0.75 * w\n",
    "    y_min_valid = 0.25 * h\n",
    "    y_max_valid = 0.75 * h\n",
    "\n",
    "    best_box = None\n",
    "    max_conf = -1\n",
    "\n",
    "    for box in boxes:\n",
    "        if box.conf < conf_thresh:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        cx = (x1 + x2) / 2\n",
    "        cy = (y1 + y2) / 2\n",
    "\n",
    "        if not (x_min_valid <= cx <= x_max_valid and y_min_valid <= cy <= y_max_valid):\n",
    "            continue\n",
    "\n",
    "        if box.conf > max_conf:\n",
    "            max_conf = box.conf\n",
    "            best_box = (cx, cy)\n",
    "\n",
    "    if best_box:\n",
    "        cx, cy = best_box\n",
    "        return (cx / w, cy / h)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# ─── ZOOM FUNCTION ────────────────────────────────────────────────\n",
    "def apply_zoom(image, center, zoom_factor):\n",
    "    h, w = image.shape[:2]\n",
    "    cx = int(center[0] * w)\n",
    "    cy = int(center[1] * h)\n",
    "\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "\n",
    "    x1 = max(cx - new_w // 2, 0)\n",
    "    y1 = max(cy - new_h // 2, 0)\n",
    "    x2 = min(cx + new_w // 2, w)\n",
    "    y2 = min(cy + new_h // 2, h)\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "    zoomed = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    return zoomed\n",
    "\n",
    "def process_overcanopy_videos():\n",
    "    print(\"🔍 Processing over-canopy videos...\")\n",
    "    with open(GT_VIDEO_CSV, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(\"CSV file has insufficient rows.\")\n",
    "\n",
    "    # second_line = lines[1]\n",
    "    # if not re.search(r\"Point\\\\s*\\\\d+\", second_line, re.IGNORECASE):\n",
    "    #     print(\"⚠️ Skipping processing — 'Point X' pattern not found in second line.\")\n",
    "    #     return\n",
    "\n",
    "    df = pd.read_csv(GT_VIDEO_CSV, skiprows=[1])\n",
    "    model = YOLO(str(CROWN_MODEL_PATH))\n",
    "    log_data = []\n",
    "    summary_failures = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            point = str(row[\"point\"]).strip()\n",
    "            video_name_raw = row.get(VIDEO_NAME, \"\")\n",
    "            if pd.isna(video_name_raw) or str(video_name_raw).strip() == \"\":\n",
    "                summary_failures.append((f\"{point}\", \"Empty VIDEO_NAME, skipping\"))\n",
    "                continue\n",
    "            video_name = str(video_name_raw).strip().upper()\n",
    "        except Exception as e:\n",
    "            summary_failures.append((f\"{point}\", f\"Malformed row: {e}\"))\n",
    "            continue\n",
    "\n",
    "        video_path = VIDEO_INPUT_DIR / f\"{video_name.lower()}.mp4\"\n",
    "        if not video_path.exists():\n",
    "            summary_failures.append((video_name, \"Video not found\"))\n",
    "            continue\n",
    "\n",
    "        output_folder = OUTPUT_BASE / point.lower().replace(\" \", \"\") / \"Orbits\"\n",
    "        images_folder = output_folder / \"images\"\n",
    "        images_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            summary_failures.append((video_name, \"Could not open video\"))\n",
    "            continue\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "\n",
    "        if duration <= TARGET_TIME:\n",
    "            summary_failures.append((video_name, f\"Video too short ({duration:.2f}s)\"))\n",
    "            cap.release()\n",
    "            continue\n",
    "\n",
    "        # ─── IMAGE EXTRACTION ─────────────────────────────────────────\n",
    "        zoom_center = None\n",
    "        total_images = 4 * (images_per_quadrant + 1)\n",
    "        timestamps = [TARGET_TIME + i * ((duration - TARGET_TIME) / total_images) for i in range(total_images)]\n",
    "\n",
    "        saved_any_frame = False\n",
    "\n",
    "        for i, ts in enumerate(timestamps):\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC, ts * 1000)\n",
    "            success, frame = cap.read()\n",
    "\n",
    "            # EDIT: save the images into the file\n",
    "            # if success:\n",
    "            #     raw_frame_name = f\"{video_name}_raw_{i}.jpg\" if i > 0 else f\"{video_name}_raw_y+.jpg\"\n",
    "            #     raw_out_path = images_folder / raw_frame_name\n",
    "            #     cv2.imwrite(str(raw_out_path), frame, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "\n",
    "            if not success:\n",
    "                summary_failures.append((video_name, f\"Failed to read frame at t={ts:.2f}s\"))\n",
    "                continue\n",
    "\n",
    "            detected_center = detect_crown_center(frame, model, previous_center=zoom_center)\n",
    "            if detected_center is not None:\n",
    "                zoom_center = detected_center\n",
    "            elif zoom_center is None:\n",
    "                zoom_center = (0.5, 0.5)\n",
    "\n",
    "            zoomed = apply_zoom(frame, zoom_center, ZOOM_FACTOR)\n",
    "\n",
    "            # 🔲 Draw black X to indicate zoom center\n",
    "            zh, zw = zoomed.shape[:2]\n",
    "            x = int(zoom_center[0] * zw)\n",
    "            y = int(zoom_center[1] * zh)\n",
    "            cv2.line(zoomed, (x - 30, y - 30), (x + 30, y + 30), (0, 0, 0), 3)\n",
    "            cv2.line(zoomed, (x - 30, y + 30), (x + 30, y - 30), (0, 0, 0), 3)\n",
    "\n",
    "            if i == 0:\n",
    "                fname = f\"{video_name}_zoomed_y+.jpg\"\n",
    "            else:\n",
    "                fname = f\"{video_name}_zoomed_{i}.jpg\"\n",
    "\n",
    "            out_path = images_folder / fname\n",
    "            cv2.imwrite(str(out_path), zoomed, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            saved_any_frame = True\n",
    "\n",
    "            log_data.append({\n",
    "                \"point\": point,\n",
    "                \"video_name\": video_name,\n",
    "                \"image_name\": fname,\n",
    "                \"timestamp_sec\": round(ts, 2)\n",
    "            })\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if not saved_any_frame:\n",
    "            summary_failures.append((video_name, \"No frames successfully extracted\"))\n",
    "            print(f\"⚠️ No frames saved for {video_name}. Check video duration and timestamps.\")\n",
    "\n",
    "    # ─── SAVE LOG CSV (Update-Only) ───────────────────────────────────\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    LOG_CSV_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if LOG_CSV_PATH.exists():\n",
    "        existing_log_df = pd.read_csv(LOG_CSV_PATH)\n",
    "        updated_log_df = existing_log_df[~existing_log_df['video_name'].isin(log_df['video_name'].unique())]\n",
    "        combined_log_df = pd.concat([updated_log_df, log_df], ignore_index=True)\n",
    "    else:\n",
    "        combined_log_df = log_df\n",
    "\n",
    "    combined_log_df.to_csv(LOG_CSV_PATH, index=False)\n",
    "    print(f\"\\n📝 Image log updated and saved to: {LOG_CSV_PATH}\")\n",
    "\n",
    "    if summary_failures:\n",
    "        print(\"\\n📊 Summary of Videos Not Processed:\")\n",
    "        for vid, reason in summary_failures:\n",
    "            print(f\"  - {vid}: {reason}\")\n",
    "    else:\n",
    "        print(\"\\n✅ All videos processed successfully.\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SECTION 3: Heading recalibration\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def calculate_heading(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    x = math.sin(dlon) * math.cos(lat2)\n",
    "    y = math.cos(lat1)*math.sin(lat2) - math.sin(lat1)*math.cos(lat2)*math.cos(dlon)\n",
    "    bearing = math.atan2(x, y)\n",
    "    return (math.degrees(bearing) + 360) % 360\n",
    "\n",
    "def extract_gps_from_srt(srt_file):\n",
    "    coords, current_time = [], None\n",
    "    with open(srt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            time_match = re.match(r'(\\d{2}):(\\d{2}):(\\d{2})', line)\n",
    "            if time_match:\n",
    "                h, m, s = map(int, time_match.groups())\n",
    "                current_time = h * 3600 + m * 60 + s\n",
    "\n",
    "            if 'latitude:' in line and 'longitude:' in line and current_time:\n",
    "                lat_match = re.search(r'\\[latitude:\\s*([-\\d.]+)\\]', line)\n",
    "                lon_match = re.search(r'\\[longitude:\\s*([-\\d.]+)\\]', line)\n",
    "                if lat_match and lon_match and current_time is not None:\n",
    "                    lat = float(lat_match.group(1))\n",
    "                    lon = float(lon_match.group(1))\n",
    "                    coords.append((lat, lon, current_time))\n",
    "    return coords\n",
    "\n",
    "def recalibrate_heading():\n",
    "    gt_df, log_df = pd.read_csv(GT_VIDEO_CSV), pd.read_csv(LOG_CSV_PATH)\n",
    "    gt_df[VIDEO_NAME] = gt_df[VIDEO_NAME].astype(str).str.strip().str.replace(\".MP4\", \"\", case=False)\n",
    "    log_df[\"video_name\"] = log_df[\"video_name\"].astype(str).str.strip().str.replace(\".MP4\", \"\", case=False)\n",
    "\n",
    "    total_bins = (1 + images_per_quadrant) * 4\n",
    "    bin_width = 360 / total_bins\n",
    "\n",
    "    for idx, row in log_df.iterrows():\n",
    "        if \"y+\" not in row[\"image_name\"]: continue\n",
    "        gt_match = gt_df[(gt_df[VIDEO_NAME].str.upper() == row[\"video_name\"].upper()) & (gt_df[\"point\"].astype(str).str.lower() == row[\"point\"].lower())]\n",
    "        if gt_match.empty: continue\n",
    "\n",
    "        tree_lat = float(gt_match.iloc[0][\"Latitude\"])\n",
    "        tree_lon = float(gt_match.iloc[0][\"Longitude\"])\n",
    "        srt_file = SRT_PATH / f\"{row['video_name'].upper()}.SRT\"\n",
    "        if not srt_file.exists(): continue\n",
    "\n",
    "        coords = extract_gps_from_srt(srt_file)\n",
    "        closest = min(coords, key=lambda x: abs(x[2] - TARGET_TIME), default=None)\n",
    "        if not closest: continue\n",
    "\n",
    "        heading = calculate_heading(tree_lat, tree_lon, closest[0], closest[1])\n",
    "        adj = (heading - REFERENCE_ANGLE + 360) % 360\n",
    "        index = round(adj / bin_width) % total_bins\n",
    "        log_df.loc[idx, \"heading\"] = round(heading, 2)\n",
    "        log_df.loc[idx, \"adjustment_angle\"] = round(adj, 2)\n",
    "        log_df.loc[idx, \"adjustment_index\"] = index\n",
    "\n",
    "    # Save CSV\n",
    "    log_df.to_csv(LOG_CSV_PATH, index=False)\n",
    "    print(f\"✅ Updated log with headings → {LOG_CSV_PATH}\")\n",
    "\n",
    "    # Summary\n",
    "    #print(f\"\\n✅ Completed processing {len(tasks_images)} / {len(tasks_images)} images.\")\n",
    "    print(f\"📝 CSV log saved to: {LOG_CSV_PATH}\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SECTION 4: Blob extraction\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def process_red_blobs():\n",
    "    df = pd.read_csv(LOG_CSV_PATH)\n",
    "    df[\"max_blob_grey\"] = df.get(\"max_blob_grey\", \"\")\n",
    "    df[\"max_blob_red\"] = df.get(\"max_blob_red\", \"\")\n",
    "    tasks = []\n",
    "    #processed = 0\n",
    "    empty_folders =[]\n",
    "\n",
    "    for folder in OUTPUT_BASE.glob(\"**/Orbits/images\"):\n",
    "        task_count = 0\n",
    "        for img_path in sorted(folder.glob(\"*.jpg\")):  # 🔁 Now sorted alphabetically\n",
    "            if \"_grey\" in img_path.name or \"_blob\" in img_path.name:\n",
    "                continue\n",
    "            matches = df.index[df[\"image_name\"] == img_path.name].tolist()\n",
    "            if matches:\n",
    "                tasks.append((img_path, matches[0]))\n",
    "                task_count +=1\n",
    "        if task_count == 0:\n",
    "            empty_folders.append(str(folder.parent))  # One level up from /images\n",
    "\n",
    "\n",
    "    for img_path, idx in tqdm(tasks, desc=\"🧠 Red-blob mask\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None: continue\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.bitwise_or(cv2.inRange(hsv, lower_red1, upper_red1), cv2.inRange(hsv, lower_red2, upper_red2))\n",
    "        inv_mask = cv2.bitwise_not(mask)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_blob_grey = max([cv2.contourArea(c) for c in contours], default=0)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_colored = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "        red = cv2.bitwise_and(img, img, mask=mask)\n",
    "        grey = cv2.bitwise_and(gray_colored, gray_colored, mask=inv_mask)\n",
    "        result = cv2.add(red, grey)\n",
    "        grey_path = img_path.with_name(img_path.stem + \"_grey.jpg\")\n",
    "        cv2.imwrite(str(grey_path), result)\n",
    "\n",
    "        # Generate blob output\n",
    "        grey_img = cv2.imread(str(grey_path))\n",
    "        mask = cv2.bitwise_or(cv2.inRange(cv2.cvtColor(grey_img, cv2.COLOR_BGR2HSV), lower_red1, upper_red1),\n",
    "                              cv2.inRange(cv2.cvtColor(grey_img, cv2.COLOR_BGR2HSV), lower_red2, upper_red2))\n",
    "        inv = cv2.bitwise_not(mask)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_blob_red = max([cv2.contourArea(c) for c in contours], default=0)\n",
    "\n",
    "        white = np.full_like(grey_img, 255)\n",
    "        blob = cv2.add(cv2.bitwise_and(grey_img, grey_img, mask=mask),\n",
    "                       cv2.bitwise_and(white, white, mask=inv))\n",
    "        blob_path = img_path.with_name(img_path.stem + \"_blob.jpg\")\n",
    "        cv2.imwrite(str(blob_path), blob)\n",
    "\n",
    "        df.at[idx, \"max_blob_grey\"] = int(max_blob_grey)\n",
    "        df.at[idx, \"max_blob_red\"] = int(max_blob_red)\n",
    "\n",
    "    df.to_csv(LOG_CSV_PATH, index=False)\n",
    "    print(f\"✅ Red-blob metrics updated → {LOG_CSV_PATH}\")\n",
    "\n",
    "    if empty_folders:\n",
    "        print(\"\\n📭 The following folders had no valid images for processing:\")\n",
    "    for folder in empty_folders:\n",
    "        print(f\"  - {folder}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# SECTION 5: Final analysis and scoring\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def perform_final_analysis():\n",
    "    gt_log = pd.read_csv(GT_LOG_CSV)\n",
    "    image_log = pd.read_csv(LOG_CSV_PATH)\n",
    "\n",
    "    opposite_map = {\"8\": \"4\", \"3\": \"7\", \"1\": \"5\", \"2\": \"6\", \"4\": \"8\", \"7\": \"3\", \"5\": \"1\", \"6\": \"2\"}\n",
    "\n",
    "    def extract_img_number(name):\n",
    "        return name.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    def count_ground_truth(group):\n",
    "        group['img_num'] = group['image_name'].apply(extract_img_number).astype(str)\n",
    "        group['Ripe'] = group['Ripe'].astype(int)\n",
    "\n",
    "        if (group['Ripe'] == 2).any():\n",
    "            return 2\n",
    "\n",
    "        ripe_imgs = group[group['Ripe'] == 1]['img_num'].tolist()\n",
    "        all_imgs = group['img_num'].tolist()\n",
    "\n",
    "        ripe_flags = [img in ripe_imgs for img in all_imgs]\n",
    "        ripe_flags_looped = ripe_flags + ripe_flags[:3]\n",
    "\n",
    "        max_consecutive = 0\n",
    "        current = 0\n",
    "        for val in ripe_flags_looped:\n",
    "            if val:\n",
    "                current += 1\n",
    "                max_consecutive = max(max_consecutive, current)\n",
    "            else:\n",
    "                current = 0\n",
    "\n",
    "        if max_consecutive >= 5:\n",
    "            return 2\n",
    "        elif max_consecutive >= 1:\n",
    "            for img in ripe_imgs:\n",
    "                if img in opposite_map and opposite_map[img] in ripe_imgs:\n",
    "                    return 2\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    final_rows = []\n",
    "    for point, group in gt_log.groupby(\"point\"):\n",
    "        gt_count = count_ground_truth(group)\n",
    "        final_rows.append({\"pointX\": point, \"ground_truth\": gt_count, \"orbits\": \"n/a\"})\n",
    "    final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "    def extract_image_number(name):\n",
    "        return Path(name).stem.split(\"_\")[-1]\n",
    "\n",
    "    image_log[\"pointX\"] = image_log[\"point\"]\n",
    "    image_log[\"image_num\"] = image_log[\"image_name\"].apply(extract_image_number)\n",
    "\n",
    "    orbit_counts = {}\n",
    "    for point, group in image_log.groupby(\"pointX\"):\n",
    "        high_spikes = group[group[\"max_blob_grey\"] > THRESHOLD].copy()\n",
    "        high_spikes[\"section\"] = high_spikes[\"image_num\"].map(image_to_section)\n",
    "        sections = high_spikes[\"section\"].dropna().astype(int).tolist()\n",
    "        unique_sections = set(sections)\n",
    "\n",
    "        if len(unique_sections) >= 5:\n",
    "            orbit_value = 2\n",
    "        elif len(unique_sections) >= 1:\n",
    "            found_opposites = any(OPPOSITE_SECTIONS.get(sec) in unique_sections for sec in unique_sections)\n",
    "            orbit_value = 2 if found_opposites else 1\n",
    "        else:\n",
    "            orbit_value = 0\n",
    "\n",
    "        orbit_counts[point] = orbit_value\n",
    "\n",
    "    # ✅ Vectorized assignment (clean and safe)\n",
    "    final_df[\"orbits\"] = final_df[\"pointX\"].map(orbit_counts).fillna(\"n/a\")\n",
    "\n",
    "    def binary_check(row):\n",
    "        try:\n",
    "            if row[\"orbits\"] == \"n/a\":\n",
    "                return \"n/a\"\n",
    "            gt = int(row[\"ground_truth\"])\n",
    "            orb = int(row[\"orbits\"])\n",
    "            return \"good\" if gt > 0 and orb > 0 else \"bad\"\n",
    "        except:\n",
    "            return \"n/a\"\n",
    "\n",
    "    final_df[\"binary_check\"] = final_df.apply(binary_check, axis=1)\n",
    "\n",
    "    valid_binary = final_df[final_df[\"binary_check\"] != \"n/a\"]\n",
    "    total_rows = len(valid_binary)\n",
    "    good_matches = (valid_binary[\"binary_check\"] == \"good\").sum()\n",
    "    binary_accuracy_percent = 100 * good_matches / total_rows if total_rows > 0 else 0\n",
    "\n",
    "    def row_accuracy(row):\n",
    "        try:\n",
    "            if row[\"orbits\"] == \"n/a\":\n",
    "                return \"n/a\"\n",
    "            gt = int(row[\"ground_truth\"])\n",
    "            orb = int(row[\"orbits\"])\n",
    "            if gt == 0 and orb == 0:\n",
    "                return 1.0\n",
    "            elif gt == 0 or orb == 0:\n",
    "                return 0.0\n",
    "            return min(gt, orb) / max(gt, orb)\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    final_df[\"accuracy_score\"] = final_df.apply(row_accuracy, axis=1)\n",
    "\n",
    "    valid_numeric = final_df[final_df[\"orbits\"] != \"n/a\"].copy()\n",
    "    valid_numeric[\"orbits\"] = valid_numeric[\"orbits\"].astype(int)\n",
    "\n",
    "    total_gt = valid_numeric[\"ground_truth\"].astype(int).sum()\n",
    "    total_orb = valid_numeric[\"orbits\"].sum()\n",
    "\n",
    "    # New total accuracy: average of per-row accuracy_score\n",
    "    valid_scores = final_df[final_df[\"accuracy_score\"] != \"n/a\"]\n",
    "    total_accuracy_percent = 100 * valid_scores[\"accuracy_score\"].astype(float).mean() if not valid_scores.empty else 0.0\n",
    "\n",
    "    print(f\"[✅] Binary Match Accuracy: {binary_accuracy_percent:.2f}% ({good_matches}/{total_rows})\")\n",
    "    print(f\"[✅] Overall Count Accuracy: {total_accuracy_percent:.2f}%\")\n",
    "    print(f\"[✅] Total Ground Truth (Ripe FFB): {total_gt}\")\n",
    "    print(f\"[✅] Total Orbit Count (Ripe FFB):  {total_orb}\")\n",
    "\n",
    "    final_df.to_csv(FINAL_OUTPUT_PATH, index=False)\n",
    "    print(f\"\\n📊 Summary of Ground Truth and Orbit Analysis:\\n{final_df}\")\n",
    "\n",
    "# ─── MAIN ─────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    if PROCESS_IMAGES:\n",
    "        process_gt_images()\n",
    "    if PROCESS_VIDEOS:\n",
    "        process_overcanopy_videos()\n",
    "    if RECALIBRATE_HEADING:\n",
    "        recalibrate_heading()\n",
    "    if EXTRACT_REDBLOB:\n",
    "        process_red_blobs()\n",
    "    if FINAL_ANALYSIS:\n",
    "        perform_final_analysis()\n",
    "    print(\"\\n✅ All enabled processing steps completed.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
